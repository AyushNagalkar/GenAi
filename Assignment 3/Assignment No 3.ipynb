{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7b56c2b",
   "metadata": {},
   "source": [
    "# Assignment 3: Fine-tune GPT-2 for Creative Story Generation\n",
    "This notebook fine-tunes GPT-2 Medium on a story dataset to generate creative stories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24d28a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pip 25.3 from C:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip (python 3.10)\n",
      "Requirement already satisfied: transformers in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.57.6)\n",
      "Requirement already satisfied: datasets in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: accelerate in c:\\users\\ayush\\appdata\\roaming\\python\\python310\\site-packages (1.12.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ayush\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2025.10.23)\n",
      "Requirement already satisfied: requests in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ayush\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (23.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\ayush\\appdata\\roaming\\python\\python310\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\ayush\\appdata\\roaming\\python\\python310\\site-packages (from accelerate) (7.1.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from accelerate) (2.7.1+cu118)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\ayush\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ayush\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\ayush\\appdata\\roaming\\python\\python310\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ayush\\appdata\\roaming\\python\\python310\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ayush\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip -v install transformers datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f570040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Check GPU availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec991fe",
   "metadata": {},
   "source": [
    "## Step 1: Load GPT-2 Medium Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "881c3374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: gpt2-medium\n",
      "Parameters: 354,823,168\n"
     ]
    }
   ],
   "source": [
    "# Load GPT-2 Medium (better quality)\n",
    "model_name = \"gpt2-medium\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "# Set padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "print(f\"Model loaded: {model_name}\")\n",
    "print(f\"Parameters: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bfcab9",
   "metadata": {},
   "source": [
    "## Step 2: Load and Prepare Story Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94068457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 5000 stories\n",
      "\n",
      "Sample story:\n",
      "One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\n",
      "\n",
      "Lily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\"\n",
      "\n",
      "Together, they shared the needle and sewed the button on Lily's shirt. It was not difficult for them b...\n"
     ]
    }
   ],
   "source": [
    "# Load TinyStories dataset - specifically designed for story generation\n",
    "dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train[:5000]\")\n",
    "print(f\"Dataset size: {len(dataset)} stories\")\n",
    "print(f\"\\nSample story:\\n{dataset[0]['text'][:500]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4dbc127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete!\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "print(f\"Tokenization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f13722",
   "metadata": {},
   "source": [
    "## Step 3: Fine-tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96aa0de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning...\n"
     ]
    }
   ],
   "source": [
    "# Data collator for language modeling\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./story_gpt2_model\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=5e-5,\n",
    "    warmup_steps=100,\n",
    "    logging_steps=50,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    fp16=torch.cuda.is_available(),  # Use mixed precision if GPU available\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "print(\"Starting fine-tuning...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc4b2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='199' max='939' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [199/939 1:49:41 < 6:52:00, 0.03 it/s, Epoch 0.63/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.061100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.817700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.785000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()\n",
    "print(\"\\nFine-tuning complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f94e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"./story_gpt2_model/final\")\n",
    "tokenizer.save_pretrained(\"./story_gpt2_model/final\")\n",
    "print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88630f9",
   "metadata": {},
   "source": [
    "## Step 4: Generate Stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54137257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_story(prompt, max_length=300, temperature=0.8, top_p=0.92):\n",
    "    \"\"\"\n",
    "    Generate a creative story from a prompt.\n",
    "    \n",
    "    Args:\n",
    "        prompt: Starting text for the story (e.g., \"Once upon a time\")\n",
    "        max_length: Maximum length of generated story\n",
    "        temperature: Higher = more creative (0.7-1.0 recommended)\n",
    "        top_p: Nucleus sampling parameter (0.9-0.95 recommended)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Encode prompt\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Generate story\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs,\n",
    "            max_length=max_length,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            do_sample=True,\n",
    "            num_return_sequences=1,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            repetition_penalty=1.2,\n",
    "            no_repeat_ngram_size=3\n",
    "        )\n",
    "    \n",
    "    # Decode and return story\n",
    "    story = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return story\n",
    "\n",
    "print(\"Story generation function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b5ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample stories\n",
    "prompts = [\n",
    "    \"Once upon a time, in a magical forest,\",\n",
    "    \"The little girl found a mysterious box in her grandmother's attic.\",\n",
    "    \"A brave knight set out on a journey to find the lost treasure.\"\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"GENERATED STORIES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, prompt in enumerate(prompts, 1):\n",
    "    print(f\"\\n--- Story {i} ---\")\n",
    "    print(f\"Prompt: {prompt}\\n\")\n",
    "    story = generate_story(prompt)\n",
    "    print(story)\n",
    "    print(\"\\n\" + \"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b25945",
   "metadata": {},
   "source": [
    "## Step 5: Interactive Story Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821599a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive story generation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"INTERACTIVE STORY GENERATOR\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Enter a story prompt to generate a creative story.\")\n",
    "print(\"Type 'quit' to exit.\\n\")\n",
    "\n",
    "while True:\n",
    "    user_prompt = input(\"Enter your story prompt: \").strip()\n",
    "    \n",
    "    if user_prompt.lower() == 'quit':\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    if not user_prompt:\n",
    "        print(\"Please enter a prompt!\\n\")\n",
    "        continue\n",
    "    \n",
    "    print(\"\\nGenerating story...\\n\")\n",
    "    story = generate_story(user_prompt, max_length=350)\n",
    "    print(\"Generated Story:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(story)\n",
    "    print(\"-\" * 40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f091c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142c1759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fe3fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92cb6f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d0b455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d787d0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7701d522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93b4dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2575b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120bf441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b96fa02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bd7f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5989b311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b39730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f89b084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
