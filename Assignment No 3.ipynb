{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7b56c2b",
   "metadata": {},
   "source": [
    "# Assignment 3: Fine-tune GPT-2 for Story Generation\n",
    "\n",
    "This notebook trains GPT-2 to write creative stories.\n",
    "\n",
    "**Setup:** Go to Runtime → Change runtime type → Select GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d28a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "!pip install -q transformers datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f570040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Check if GPU is available\n",
    "print(\"Using GPU:\" if torch.cuda.is_available() else \"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec991fe",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881c3374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GPT-2 model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-medium\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bfcab9",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94068457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load story dataset (5000 stories)\n",
    "dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train[:5000]\")\n",
    "print(f\"Loaded {len(dataset)} stories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dbc127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize stories\n",
    "def tokenize(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=256, padding=\"max_length\")\n",
    "\n",
    "dataset = dataset.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "print(\"Data ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f13722",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aa0de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/story_model\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    logging_steps=100,\n",
    "    save_steps=500,\n",
    "    fp16=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    ")\n",
    "\n",
    "print(\"Training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc4b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training\n",
    "trainer.train()\n",
    "print(\"Training done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f94e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save_pretrained(\"/content/story_model/final\")\n",
    "tokenizer.save_pretrained(\"/content/story_model/final\")\n",
    "print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88630f9",
   "metadata": {},
   "source": [
    "## Generate Stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54137257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate stories\n",
    "def generate_story(prompt):\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_length=300,\n",
    "        temperature=0.8,\n",
    "        top_p=0.92,\n",
    "        do_sample=True\n",
    "    )\n",
    "    \n",
    "    story = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return story\n",
    "\n",
    "print(\"Ready to generate stories!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b5ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with sample prompts\n",
    "prompts = [\n",
    "    \"Once upon a time, in a magical forest,\",\n",
    "    \"The little girl found a mysterious box\",\n",
    "    \"A brave knight set out on a journey\"\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    print(generate_story(prompt))\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b25945",
   "metadata": {},
   "source": [
    "## Try Your Own Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "821599a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi i am ayush \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'generate_story' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m my_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter Your Prompt Here : \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(my_prompt)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgenerate_story\u001b[49m(my_prompt))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'generate_story' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate story from your own prompt\n",
    "my_prompt = input(\"Enter Your Prompt Here : \")\n",
    "print(my_prompt)\n",
    "print(generate_story(my_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfe2b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
